{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare tangential shear profiles from the extragalactic and object catalogs for DC2 Run 2.1i\n",
    "\n",
    "This notebook can be run at NERSC or CC-IN2P3 where the DESC DC2 products are stored. You need to be a DESC member to be able to access those. \n",
    "\n",
    "This was put together using:\n",
    "- the DC2 analysis tutorials (in particular `matching_fof.ipynb` and `object_gcr_2_lensing_cuts.ipynb`)\n",
    "- the CLMM usage examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "\n",
    "# DC2 catalog-related imports\n",
    "import FoFCatalogMatching\n",
    "import GCRCatalogs\n",
    "from GCR import GCRQuery\n",
    "\n",
    "#CLMM imports\n",
    "try: import clmm\n",
    "except:\n",
    "    import notebook_install\n",
    "    notebook_install.install_clmm_pipeline(upgrade=False)\n",
    "    import clmm\n",
    "import clmm.utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the catalogs\n",
    "- DC2 object catalog\n",
    "- DC2 extragalactic catalog (cosmoDC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cat = GCRCatalogs.load_catalog('dc2_object_run2.1i_dr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extragalactic_cat = GCRCatalogs.load_catalog('cosmoDC2_v1.1.4_small',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify one halo in the extragalactic catalog\n",
    "Choosing the most massive one below z = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of massive halos in a given redshift and mass range\n",
    "mmin = 5.e14\n",
    "zmax = 0.4\n",
    "\n",
    "massive_halos = extragalactic_cat.get_quantities(['halo_mass','hostHaloMass','redshift','ra', 'dec'],\\\n",
    "                                                 filters=[f'halo_mass > {mmin}','is_central==True',\n",
    "                                                          f'redshift<{zmax}'])\n",
    "\n",
    "N_cl = len(massive_halos['halo_mass'])\n",
    "print(f'There are {N_cl} clusters available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the most massive one\n",
    "select = massive_halos['halo_mass'] == np.max(massive_halos['halo_mass'])\n",
    "ra_cl = massive_halos['ra'][select][0]\n",
    "dec_cl = massive_halos['dec'][select][0]\n",
    "z_cl = massive_halos['redshift'][select][0]\n",
    "mass_cl =massive_halos['halo_mass'][select][0]\n",
    "print (f'The most massive cluster is in ra = {ra_cl:.2f} deg, dec = {dec_cl:.2f} deg, z = {z_cl:.2f}, with mass = {mass_cl:.2e} Msun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selection of background galaxies around the cluster\n",
    "- Define cuts on the cosmoDC2 and object catalogs. We also add some WL quality cuts for the object catalog.\n",
    "- The two catalogs will then be matched to end up with the same selection of galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coordinate filter to be applied applied to both extragalactic and object catalog\n",
    "ra_min, ra_max = ra_cl-0.35, ra_cl+0.35\n",
    "dec_min, dec_max = dec_cl-0.35, dec_cl+0.35\n",
    "\n",
    "coord_filters = [\n",
    "    f'ra >= {ra_min}',\n",
    "    f'ra < {ra_max}',\n",
    "    f'dec >= {dec_min}',\n",
    "    f'dec < {dec_max}',\n",
    "]\n",
    "\n",
    "# Redshift cut to be applied to the extragalactic catalog. The object catalog does not have redshift information.\n",
    "z_min = z_cl + 0.1\n",
    "redshift_filters = [\n",
    "    (np.isfinite, 'redshift'),\n",
    "    f'redshift > {z_min}',\n",
    "]\n",
    "\n",
    "# Magnitude cut to be applied to both catalogs\n",
    "mag_filters = [\n",
    "    (np.isfinite, 'mag_i'),\n",
    "    'mag_i < 24.5',\n",
    "]\n",
    "\n",
    "\n",
    "# Following DC2 tutorials, basics cuts to be applied to the object catalog\n",
    "object_basic_cuts = [\n",
    "    GCRQuery('extendedness > 0'),     # Extended objects\n",
    "    GCRQuery((np.isfinite, 'mag_i')), # Select objects that have i-band magnitudes\n",
    "    GCRQuery('clean'), # The source has no flagged pixels (interpolated, saturated, edge, clipped...) \n",
    "                       # and was not skipped by the deblender\n",
    "    GCRQuery('xy_flag == 0'),                                      # Flag for bad centroid measurement\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_flag == 0'),            # Error code returned by shape measurement code\n",
    "    GCRQuery((np.isfinite, 'ext_shapeHSM_HsmShapeRegauss_sigma')), # Shape measurement uncertainty should not be NaN\n",
    "]\n",
    "\n",
    "# Adding the total ellipticity quantity to the object catalog\n",
    "object_cat.add_quantity_modifier('shape_hsm_regauss_etot', \n",
    "                                 (np.hypot, 'ext_shapeHSM_HsmShapeRegauss_e1', 'ext_shapeHSM_HsmShapeRegauss_e2'), \n",
    "                                 overwrite=True)\n",
    "\n",
    "\n",
    "# Following DC2 tutorials, additional WL quality cuts to be applied to the object catalog\n",
    "object_properties_cuts = [\n",
    "    GCRQuery('snr_i_cModel > 10'),                              # SNR > 10\n",
    "    GCRQuery('mag_i_cModel < 24.5'),                            # cModel imag brighter than 24.5\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_resolution >= 0.3'), # Sufficiently resolved galaxies compared to PSF\n",
    "    GCRQuery('shape_hsm_regauss_etot < 2'),                     # Total distortion in reasonable range\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4'),      # Shape measurement errors reasonable\n",
    "    # New cut on blendedness:\n",
    "    GCRQuery('blendedness < 10**(-0.375)')                      # Avoid spurious detections and those contaminated by blends\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quanitities from cosmoDC2 catalog, using the filters we just defined.\n",
    "extragal_data = extragalactic_cat.get_quantities(['ra', 'dec', 'shear_1', 'shear_2', \n",
    "                                                  'ellipticity_1_true', 'ellipticity_2_true',\n",
    "                                                  'redshift', 'convergence', 'galaxy_id'], \n",
    "                                                 filters=(coord_filters + mag_filters + redshift_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quanitities from object catalog, using the filters we just defined.\n",
    "# The field under scrutiny falls in tract 3448 of the object catalog. \n",
    "# Specifying that tract using native_filters speeds up the process but is not required.\n",
    "\n",
    "object_data = object_cat.get_quantities(['ra', 'dec',\n",
    "                                         'ext_shapeHSM_HsmShapeRegauss_e1','ext_shapeHSM_HsmShapeRegauss_e2', \n",
    "                                         'id'],\n",
    "                                        native_filters=['tract == 3448'],\n",
    "                                        filters=(coord_filters + object_basic_cuts + object_properties_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Match the 2 catalogs\n",
    "\n",
    "Using the `FoFCatalogMatching` method, as examplified in the DC2 analysis tutorial. As mentioned in the tutorial, *`FoFCatalogMatching.match` takes a dictionary of catalogs to match and a friends-of-friends linking length. \n",
    "Because the \"catalog\" is not an astropy table or pandas dataframe, `len(truth_coord)` won't give the actual length of the table so we need to specify `catalog_len_getter` so that the code knows how to get the length of the catalog.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = FoFCatalogMatching.match(\n",
    "    catalog_dict={'extragal': extragal_data, 'object': object_data},\n",
    "    linking_lengths=1.,\n",
    "    catalog_len_getter=lambda x: len(x['ra']),\n",
    ")\n",
    "\n",
    "# first we need to know which rows are from the extragalactic catalog and which are from the object\n",
    "extragal_mask = results['catalog_key'] == 'extragal'\n",
    "object_mask = ~extragal_mask\n",
    "\n",
    "# then np.bincount will give up the number of id occurrences (like historgram but with integer input)\n",
    "n_groups = results['group_id'].max() + 1\n",
    "n_extragal = np.bincount(results['group_id'][extragal_mask], minlength=n_groups)\n",
    "n_object = np.bincount(results['group_id'][object_mask], minlength=n_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify one-to-one extragal/object matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_one_group_mask = np.in1d(results['group_id'], np.flatnonzero((n_extragal == 1) & (n_object == 1)))\n",
    "\n",
    "# and then we can find the row indices in the *original* extragal/object catalogs for those 1-to-1 groups\n",
    "extragal_idx = results['row_index'][one_to_one_group_mask & extragal_mask]\n",
    "object_idx = results['row_index'][one_to_one_group_mask & object_mask]\n",
    "print(f'Number of 1-to-1 matched objects: {len(extragal_idx)}, {len(object_idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Computes the reduced tangential shear profiles from both datasets, using CLMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, dealing with the cosmoDC2 data.\n",
    "To measure a reduced tangential shear profile, the shape measurements must be made according to the $\\epsilon$ or reduced shear definition $g$. So first , we convert cosmoDC2 `shear1` and `shear2` quantities to reduced shear using the `convergence`. These become the `e1` and `e2` fields of the CLMM cluster galaxy catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = clmm.utils.convert_shapes_to_epsilon(extragal_data['shear_1'][extragal_idx],extragal_data['shear_2'][extragal_idx],\n",
    "                                              shape_definition='shear',kappa=extragal_data['convergence'][extragal_idx])\n",
    "\n",
    "# Create the background galaxy catalog as astropy table\n",
    "dat = Table([extragal_data['ra'][extragal_idx],extragal_data['dec'][extragal_idx],e1,\n",
    "      e2,extragal_data['redshift'][extragal_idx],extragal_data['galaxy_id'][extragal_idx]], \n",
    "      names=('ra','dec', 'e1', 'e2', 'z','id'))\n",
    "\n",
    "# Instantiate a CLMM cluster object and save it for later use.\n",
    "cl_from_cosmoDC2 = clmm.GalaxyCluster('CL', ra_cl, dec_cl, z_cl, dat)   \n",
    "cl_from_cosmoDC2.save('cosmoDC2_GC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second, doing the same for the DC2 object catalog\n",
    "In the object catalog, shapes are measured by `shapeHSM` which return ellipticities according to the $\\chi$ definition. Need to convert to the $\\epsilon$ definition, once again using the conversion helper function from CLMM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = clmm.utils.convert_shapes_to_epsilon(object_data['ext_shapeHSM_HsmShapeRegauss_e1'][object_idx],\n",
    "                                              object_data['ext_shapeHSM_HsmShapeRegauss_e2'][object_idx],\n",
    "                                              shape_definition='chi')\n",
    "# The conversion may create to NaN\n",
    "mask = np.isfinite(e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object catalog has no redshift information so we'll use the redshift of the matched galaxies in cosmoDC2 to create the GalaxyCluster object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the background galaxy catalog as astropy table\n",
    "dat = Table([object_data['ra'][object_idx][mask],object_data['dec'][object_idx][mask],\n",
    "             e1[mask],\n",
    "             e2[mask],\n",
    "             extragal_data['redshift'][extragal_idx][mask],\n",
    "             object_data['id'][object_idx][mask]], \n",
    "            names=('ra','dec', 'e1', 'e2', 'z','id'), masked=True)\n",
    "\n",
    "\n",
    "# Create the background galaxy catalog as astropy table and save it for later use\n",
    "cl_from_objectDC2 = clmm.GalaxyCluster('CL', ra_cl, dec_cl, z_cl, dat)  \n",
    "cl_from_objectDC2.save('objectDC2_GC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the reduced tangential shear profile from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_from_objectDC2 = clmm.load_cluster('objectDC2_GC.pkl')\n",
    "cl_from_cosmoDC2 = clmm.load_cluster('cosmoDC2_GC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = extragalactic_cat.cosmology\n",
    "bin_edges = clmm.polaraveraging.make_bins(0.15, 4, 10, method='evenlog10width')\n",
    "\n",
    "cl_from_cosmoDC2.compute_shear(geometry=\"flat\")\n",
    "profile_from_cosmoDC2 = cl_from_cosmoDC2.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)\n",
    "\n",
    "cl_from_objectDC2.compute_shear(geometry=\"flat\")\n",
    "profile_from_objectDC2 = cl_from_objectDC2.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking into account intrinsic ellipticities from cosmoDC2\n",
    "\n",
    "So far, we've used the `shear1` and `shear2` fields of cosmoDC2, i.e., we negelected the intrinsic ellipticities of the galaxies. To account for shape noise from intrinsic ellipticities, we can use the shears and unlensed ellipticities available in the cosmoDC2 catalog to build lensed ellipticities. The latter can then be used to bluid a CLMM cluster object. The resulting tangential shear profile will then include shape noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lensed_ellipticity(es1, es2, gamma1, gamma2, kappa):\n",
    "    gamma = gamma1 + gamma2*1j # shear (as a complex number)\n",
    "    es = es1 + es2*1j # intrinsic ellipticity (as a complex number)\n",
    "    g = gamma / (1.0 - kappa) # reduced shear\n",
    "    e = (es + g) / (1.0 + g.conjugate()*es) # lensed ellipticity\n",
    "    return np.real(e), np.imag(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es1 = extragal_data['ellipticity_1_true']\n",
    "es2 = extragal_data['ellipticity_2_true']\n",
    "gamma1 = extragal_data['shear_1']\n",
    "gamma2 = extragal_data['shear_2']\n",
    "kappa = extragal_data['convergence']\n",
    "\n",
    "extragal_data['ellipticity_1'] = calc_lensed_ellipticity(es1, es2, gamma1, gamma2, kappa)[0]\n",
    "extragal_data['ellipticity_2'] = calc_lensed_ellipticity(es1, es2, gamma1, gamma2, kappa)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new CLMM cluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = Table([extragal_data['ra'][extragal_idx],extragal_data['dec'][extragal_idx],\n",
    "             extragal_data['ellipticity_1'][extragal_idx],\n",
    "             extragal_data['ellipticity_2'][extragal_idx],\n",
    "             extragal_data['redshift'][extragal_idx],\n",
    "             extragal_data['galaxy_id'][extragal_idx]],\n",
    "            names=('ra','dec', 'e1', 'e2', 'z','id'))\n",
    "\n",
    "cl_from_cosmoDC2_with_e1e2 = clmm.GalaxyCluster('CL', ra_cl, dec_cl, z_cl, dat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the reduced shear profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_from_cosmoDC2_with_e1e2.compute_shear(geometry=\"flat\")\n",
    "profile_from_cosmoDC2_with_e1e2 = cl_from_cosmoDC2_with_e1e2.make_shear_profile(\"radians\", \"Mpc\", bins=bin_edges,cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results for the three profiles, obtained from the same galaxies in the two catalogs\n",
    "- from cosmoDC2, neglecting shape noise (blue points)\n",
    "- from cosmoDC2, including shape noise (orange)\n",
    "- for the DC2 object catalog (green, where the galaxies redshifts taken from cosmoDC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(profile_from_cosmoDC2['radius'],profile_from_cosmoDC2['gt'],profile_from_cosmoDC2['gt_err'], \n",
    "             marker='o',label='from cosmoDC2 g1g2')\n",
    "plt.errorbar(profile_from_cosmoDC2_with_e1e2['radius'],profile_from_cosmoDC2_with_e1e2['gt'],\n",
    "             profile_from_cosmoDC2['gt_err'],label='from cosmoDC2 e1e2')\n",
    "plt.errorbar(profile_from_objectDC2['radius'],profile_from_objectDC2['gt'],profile_from_objectDC2['gt_err'], \n",
    "             label='from DC2 objects e1e2')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('R (Mpc)')\n",
    "plt.ylabel(r'$\\langle g_t \\rangle$')\n",
    "plt.ylim([2.e-3,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cosmoDC2 (orange and blue profiles above), we see the impact of shape noise at low radii (orange/blue =w/wo intrinsic ellipticities), where the number of galaxies per bin is small (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profile_from_cosmoDC2['radius'], profile_from_cosmoDC2['n_src'], marker='o')\n",
    "[plt.axvline(x=r, ymin=0, ymax=1e3, color='k', linestyle=':') for r in profile_from_cosmoDC2['radius_min']]\n",
    "plt.ylabel('Ngal in the bin')\n",
    "plt.xlabel('R (Mpc)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-clmm",
   "language": "python",
   "name": "desc-clmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
